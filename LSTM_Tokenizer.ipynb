{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer, TFBertModel,BertForQuestionAnswering,BertForMaskedLM,BertModel\n",
    "from transformers import T5ForConditionalGeneration, T5Tokenizer\n",
    "from transformers import pipeline\n",
    "import logging\n",
    "import tensorflow as tf\n",
    "import torch\n",
    "from nltk.tokenize import sent_tokenize\n",
    "import faiss\n",
    "import numpy as np\n",
    "\n",
    "logging.getLogger(\"transformers.modeling_utils\").setLevel(logging.WARNING)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from transformers import BertTokenizer, TFBertModel\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "bert_model = TFBertModel.from_pretrained('bert-base-uncased')\n",
    "\n",
    "file_path = '/Users/t-arvio.anandi/Downloads/Train Label - Sheet1 (2).csv'\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "x_data_list = df['x_data'].tolist()\n",
    "y_data_list = df['y_data'].tolist()\n",
    "\n",
    "encoding = tokenizer(x_data_list, padding='max_length', truncation=True, return_tensors='tf', max_length=40)\n",
    "x_input_ids = encoding['input_ids']\n",
    "x_attention_mask = encoding['attention_mask']\n",
    "\n",
    "x_embeddings = bert_model(x_input_ids, attention_mask=x_attention_mask)[0].numpy() \n",
    "\n",
    "target_size = 50\n",
    "\n",
    "if x_embeddings.shape[2] < target_size:\n",
    "    padding = target_size - x_embeddings.shape[2]\n",
    "    x_embeddings_padded = np.pad(x_embeddings, ((0, 0), (0, 0), (0, padding)), 'constant')\n",
    "else:\n",
    "    x_embeddings_padded = x_embeddings[:, :, :target_size]\n",
    "\n",
    "\n",
    "def clean_label(label):\n",
    "    if pd.isna(label):\n",
    "        return [0]  \n",
    "    try:\n",
    "        return list(map(int, label.split()))\n",
    "    except:\n",
    "        return [0]  \n",
    "\n",
    "y_sequences = [clean_label(label) for label in y_data_list]\n",
    "\n",
    "y_sequences_padded = pad_sequences(y_sequences, maxlen=40, padding='post', truncating='post', value=0)  # Using -1 or another placeholder for padding\n",
    "\n",
    "print(\"Padded X Shape:\", x_embeddings.shape)\n",
    "print(\"Padded Y Shape:\", y_sequences_padded.shape)\n",
    "\n",
    "assert x_embeddings.shape[0] == 91 \n",
    "assert x_embeddings.shape[1] == 40 \n",
    "print(x_embeddings.shape[2]) \n",
    "assert y_sequences_padded.shape[0] == 91\n",
    "assert y_sequences_padded.shape[1] == 40\n",
    "print(y_sequences_padded.shape[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "\n",
    "inputs = layers.Input(shape=(40, 768)) \n",
    "\n",
    "lstm_out = layers.LSTM(64, return_sequences=True)(inputs)\n",
    "\n",
    "outputs = layers.TimeDistributed(layers.Dense(7, activation='softmax'))(lstm_out)\n",
    "\n",
    "model = models.Model(inputs, outputs)\n",
    "\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "print(model.summary())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y_sequences_padded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(x_input_ids, y_sequences_padded, test_size=0.2)\n",
    "\n",
    "model.fit(x_input_ids, y_sequences_padded, epochs=3, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "x_input_ids_np = np.array(x_input_ids)\n",
    "y_labels_np = np.array(y_labels)\n",
    "\n",
    "print(\"Shape of x_input_ids:\", x_input_ids_np.shape)\n",
    "print(\"Shape of y_labels:\", y_labels_np.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_sentence = \"What is your name?\"\n",
    "new_tokens = tokenizer.tokenize(new_sentence)\n",
    "new_input_ids = tokenizer.convert_tokens_to_ids(new_tokens)\n",
    "new_input_ids = pad_sequences([new_input_ids], maxlen=max_len, padding='post', truncating='post')\n",
    "\n",
    "predictions = model.predict(new_input_ids)\n",
    "predicted_labels = tf.argmax(predictions, axis=-1)\n",
    "\n",
    "print(\"Predicted Labels:\", predicted_labels)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
